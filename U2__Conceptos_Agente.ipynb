{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwwrm1eNbe0gwqgMQXZqvo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicaocuf/codigos_CUF_LLM_NLP/blob/main/U2__Conceptos_Agente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concepto de Agente para Reinforcement Learning"
      ],
      "metadata": {
        "id": "9kHc0EHd2Z40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "fj1SYIgZ2Ebh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entorno: Tablero 1D\n",
        "class Tablero:\n",
        "    def __init__(self):\n",
        "        self.state = random.randint(0, 3)  # El agente comienza en una casilla aleatoria (0 a 3)\n",
        "        self.goal = 4  # La casilla 4 es el objetivo\n",
        "\n",
        "    def move(self, action):\n",
        "        # El agente se mueve en el tablero\n",
        "        if action == \"L\":\n",
        "            self.state = max(0, self.state - 1)  # No puede ir más allá de 0\n",
        "        elif action == \"R\":\n",
        "            self.state = min(4, self.state + 1)  # No puede ir más allá de 4\n",
        "\n",
        "        # Recompensa: +1 si alcanza el objetivo, 0 en otro caso\n",
        "        if self.state == self.goal:\n",
        "            return 1  # Recompensa por alcanzar el objetivo\n",
        "        else:\n",
        "            return 0  # No hay recompensa en otros estados"
      ],
      "metadata": {
        "id": "_GArkZvF2F7e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agente RL\n",
        "class Agente:\n",
        "    def __init__(self, epsilon=0.5):\n",
        "        self.q_table = {}  # Tabla de valores (state-action-value)\n",
        "        self.epsilon = epsilon  # Parámetro de exploración\n",
        "        self.actions = [\"L\", \"R\"]  # Posibles acciones\n",
        "\n",
        "    def get_action(self, state):\n",
        "        # Selección de acción: exploración vs explotación\n",
        "        if random.random() < self.epsilon:  # Explorar (acción aleatoria)\n",
        "            return random.choice(self.actions)\n",
        "        else:  # Explotar (elegir la mejor acción según la tabla Q)\n",
        "            return max(self.actions, key=lambda action: self.q_table.get((state, action), 0))\n",
        "\n",
        "    def update_q_table(self, state, action, reward):\n",
        "        # Actualizar la tabla Q con una fórmula simple\n",
        "        self.q_table[(state, action)] = reward  # En este ejemplo, solo registra el último valor de recompensa"
      ],
      "metadata": {
        "id": "JY8Lvl-L2J2s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación\n",
        "tablero = Tablero()\n",
        "agente = Agente()"
      ],
      "metadata": {
        "id": "hf7njBFY2RiY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkGd9iDL1-Jl",
        "outputId": "1c31ab74-5abd-49d4-f75b-07c51d19229f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inicio de la simulación ===\n",
            "\n",
            "Episodio 1: Inicio en la posición 1\n",
            "Paso 1: Estado=1, Acción=R, Recompensa=0, Nuevo Estado=2\n",
            "Paso 2: Estado=2, Acción=R, Recompensa=0, Nuevo Estado=3\n",
            "Paso 3: Estado=3, Acción=R, Recompensa=1, Nuevo Estado=4\n",
            "¡El agente alcanzó el objetivo en el paso 3!\n",
            "\n",
            "Episodio 2: Inicio en la posición 2\n",
            "Paso 1: Estado=2, Acción=R, Recompensa=0, Nuevo Estado=3\n",
            "Paso 2: Estado=3, Acción=R, Recompensa=1, Nuevo Estado=4\n",
            "¡El agente alcanzó el objetivo en el paso 2!\n",
            "\n",
            "Episodio 3: Inicio en la posición 2\n",
            "Paso 1: Estado=2, Acción=R, Recompensa=0, Nuevo Estado=3\n",
            "Paso 2: Estado=3, Acción=L, Recompensa=0, Nuevo Estado=2\n",
            "Paso 3: Estado=2, Acción=L, Recompensa=0, Nuevo Estado=1\n",
            "Paso 4: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 6: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 7: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 9: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 10: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "\n",
            "Episodio 4: Inicio en la posición 3\n",
            "Paso 1: Estado=3, Acción=L, Recompensa=0, Nuevo Estado=2\n",
            "Paso 2: Estado=2, Acción=R, Recompensa=0, Nuevo Estado=3\n",
            "Paso 3: Estado=3, Acción=R, Recompensa=1, Nuevo Estado=4\n",
            "¡El agente alcanzó el objetivo en el paso 3!\n",
            "\n",
            "Episodio 5: Inicio en la posición 2\n",
            "Paso 1: Estado=2, Acción=L, Recompensa=0, Nuevo Estado=1\n",
            "Paso 2: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 3: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 4: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 6: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 7: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 9: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 10: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "\n",
            "Episodio 6: Inicio en la posición 1\n",
            "Paso 1: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 2: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 3: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 4: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 6: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 7: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 9: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 10: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "\n",
            "Episodio 7: Inicio en la posición 0\n",
            "Paso 1: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 2: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 3: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 4: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 6: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 7: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 9: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 10: Estado=1, Acción=R, Recompensa=0, Nuevo Estado=2\n",
            "\n",
            "Episodio 8: Inicio en la posición 3\n",
            "Paso 1: Estado=3, Acción=R, Recompensa=1, Nuevo Estado=4\n",
            "¡El agente alcanzó el objetivo en el paso 1!\n",
            "\n",
            "Episodio 9: Inicio en la posición 2\n",
            "Paso 1: Estado=2, Acción=L, Recompensa=0, Nuevo Estado=1\n",
            "Paso 2: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 3: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 4: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 6: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 7: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 9: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 10: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "\n",
            "Episodio 10: Inicio en la posición 2\n",
            "Paso 1: Estado=2, Acción=L, Recompensa=0, Nuevo Estado=1\n",
            "Paso 2: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 3: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 4: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 5: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 6: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 7: Estado=0, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 8: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n",
            "Paso 9: Estado=1, Acción=L, Recompensa=0, Nuevo Estado=0\n",
            "Paso 10: Estado=0, Acción=R, Recompensa=0, Nuevo Estado=1\n"
          ]
        }
      ],
      "source": [
        "print(\"=== Inicio de la simulación ===\")\n",
        "for episodio in range(10):  # Ejecutar 10 episodios\n",
        "    tablero.state = random.randint(0, 3)  # Reiniciar la posición del agente\n",
        "    print(f\"\\nEpisodio {episodio + 1}: Inicio en la posición {tablero.state}\")\n",
        "\n",
        "    for paso in range(10):  # Limitar el número de pasos por episodio\n",
        "        estado_actual = tablero.state\n",
        "        accion = agente.get_action(estado_actual)  # Seleccionar acción\n",
        "        recompensa = tablero.move(accion)  # Aplicar acción en el entorno\n",
        "\n",
        "        # Mostrar lo que ocurre en este paso\n",
        "        print(f\"Paso {paso + 1}: Estado={estado_actual}, Acción={accion}, Recompensa={recompensa}, Nuevo Estado={tablero.state}\")\n",
        "\n",
        "        # Actualizar la tabla Q\n",
        "        agente.update_q_table(estado_actual, accion, recompensa)\n",
        "\n",
        "        # Terminar el episodio si alcanza el objetivo\n",
        "        if recompensa == 1:\n",
        "            print(f\"¡El agente alcanzó el objetivo en el paso {paso + 1}!\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Tabla Q Final ===\")\n",
        "for key, value in sorted(agente.q_table.items()):\n",
        "    print(f\"Estado={key[0]}, Acción={key[1]}, Valor={value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9XkqXXg2Wpm",
        "outputId": "d96ed7bf-36bc-47a9-f8c0-51d64595939d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Tabla Q Final ===\n",
            "Estado=0, Acción=L, Valor=0\n",
            "Estado=0, Acción=R, Valor=0\n",
            "Estado=1, Acción=L, Valor=0\n",
            "Estado=1, Acción=R, Valor=0\n",
            "Estado=2, Acción=L, Valor=0\n",
            "Estado=2, Acción=R, Valor=0\n",
            "Estado=3, Acción=L, Valor=0\n",
            "Estado=3, Acción=R, Valor=1\n"
          ]
        }
      ]
    }
  ]
}