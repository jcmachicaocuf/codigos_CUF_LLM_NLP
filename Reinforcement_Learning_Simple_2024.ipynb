{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicaocuf/codigos_CUF_LLM_NLP/blob/main/Reinforcement_Learning_Simple_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad49a52-0424-4bc9-9751-c4c51e8849b7",
      "metadata": {
        "id": "cad49a52-0424-4bc9-9751-c4c51e8849b7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e4ac7a-2b22-48df-a65f-f6b29fe2f3b6",
      "metadata": {
        "id": "c1e4ac7a-2b22-48df-a65f-f6b29fe2f3b6"
      },
      "outputs": [],
      "source": [
        "# Parámetros de temperatura\n",
        "LOW_TEMP = 35\n",
        "HIGH_TEMP = 40\n",
        "TEMP_RANGE = HIGH_TEMP - LOW_TEMP\n",
        "NUM_ACTIONS = 2 # Incrementar, Disminuir\n",
        "\n",
        "# Parámetros de episodios\n",
        "NUM_EPISODES = 1000\n",
        "MAX_STEPS_PER_EPISODE = 30\n",
        "\n",
        "# Parámetros del modelo\n",
        "LEARNING_RATE = 0.1\n",
        "DISCOUNT_FACTOR = 0.99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6248efdc-e5a4-441a-8292-59a121d9af8d",
      "metadata": {
        "id": "6248efdc-e5a4-441a-8292-59a121d9af8d"
      },
      "outputs": [],
      "source": [
        "# Initialize Q-table with zeros\n",
        "q_table = np.zeros((TEMP_RANGE, NUM_ACTIONS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ab4678-b42e-45a1-add4-98e8660530c6",
      "metadata": {
        "id": "40ab4678-b42e-45a1-add4-98e8660530c6"
      },
      "outputs": [],
      "source": [
        "# Selecciona la acción con epsilon-greedy policy\n",
        "def select_action(state, epsilon):\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        return np.random.choice(NUM_ACTIONS)\n",
        "    else:\n",
        "        return np.argmax(q_table[state, :])\n",
        "\n",
        "# Define a function to update Q-values using Q-learning algorithm\n",
        "def update_q_value(state, action, reward, next_state):\n",
        "    if state < TEMP_RANGE and action < NUM_ACTIONS:\n",
        "        q_value = q_table[state, action]\n",
        "        max_next_q_value = np.max(q_table[next_state, :]) if next_state < TEMP_RANGE else 0\n",
        "        new_q_value = (1 - LEARNING_RATE) * q_value + LEARNING_RATE * (reward + DISCOUNT_FACTOR * max_next_q_value)\n",
        "        q_table[state, action] = new_q_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73743075-f57b-4b14-afd2-40213865df64",
      "metadata": {
        "id": "73743075-f57b-4b14-afd2-40213865df64"
      },
      "outputs": [],
      "source": [
        "# Simula el control de la temperatura de la ducha\n",
        "def simulate_shower():\n",
        "    learned_values = []\n",
        "    current_temp = np.random.randint(LOW_TEMP, HIGH_TEMP + 1)\n",
        "    for step in range(MAX_STEPS_PER_EPISODE):\n",
        "        state = int(current_temp - LOW_TEMP)\n",
        "        epsilon = 1.0 / ((step / 10) + 1)\n",
        "        action = select_action(state, epsilon)\n",
        "\n",
        "        # Acción\n",
        "        if action == 0:  # Disminuye temperatura\n",
        "            current_temp -= 1\n",
        "        elif action == 1:  # Incrementa temperatura\n",
        "            current_temp += 1\n",
        "\n",
        "        # Mantiene la temperatura dentro de los límites\n",
        "        current_temp = np.clip(current_temp, LOW_TEMP, HIGH_TEMP)\n",
        "\n",
        "        if LOW_TEMP < current_temp < HIGH_TEMP:\n",
        "            reward = 1  # Positive reward for staying within limits\n",
        "        else:\n",
        "            reward = -1  # Negative reward for reaching temperature limits\n",
        "        # Calcula la recompensa por distancia\n",
        "\n",
        "        next_state = int(current_temp - LOW_TEMP)\n",
        "        update_q_value(state, action, reward, next_state)\n",
        "\n",
        "        learned_values.append([state, action, reward, next_state])\n",
        "\n",
        "        if current_temp == LOW_TEMP or current_temp == HIGH_TEMP:\n",
        "            break\n",
        "    return pd.DataFrame(learned_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70822c5-c5f1-4ce9-9f52-a2801f5d0058",
      "metadata": {
        "id": "d70822c5-c5f1-4ce9-9f52-a2801f5d0058",
        "outputId": "7a06aba2-6efc-4885-dde7-eeadb8622540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q-table entrenada:\n",
            "[[73.84292362 82.97882534]\n",
            " [79.69804754 86.27881792]\n",
            " [86.2312142  86.36296272]\n",
            " [86.35645204 85.97036247]\n",
            " [86.11303945 -1.        ]]\n",
            "    0  1  2  3\n",
            "0   3  1  1  4\n",
            "1   4  0  1  3\n",
            "2   3  1  1  4\n",
            "3   4  0  1  3\n",
            "4   3  0  1  2\n",
            "5   2  1  1  3\n",
            "6   3  0  1  2\n",
            "7   2  1  1  3\n",
            "8   3  1  1  4\n",
            "9   4  0  1  3\n",
            "10  3  1  1  4\n",
            "11  4  0  1  3\n",
            "12  3  0  1  2\n",
            "13  2  1  1  3\n",
            "14  3  0  1  2\n",
            "15  2  1  1  3\n",
            "16  3  0  1  2\n",
            "17  2  1  1  3\n",
            "18  3  1  1  4\n",
            "19  4  1 -1  5\n"
          ]
        }
      ],
      "source": [
        "for episode in range(NUM_EPISODES):\n",
        "    l_values = simulate_shower()\n",
        "\n",
        "print(\"Q-table entrenada:\")\n",
        "print(q_table)\n",
        "print(l_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b2c7b6-aefd-4d1f-8998-72b6be2764be",
      "metadata": {
        "id": "58b2c7b6-aefd-4d1f-8998-72b6be2764be",
        "outputId": "76bdb2de-32f3-44e4-d451-8e1ed7d6192e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial temperature: 38\n",
            "Step: 1 Temperature: 37 Acción: 0\n",
            "Step: 2 Temperature: 38 Acción: 1\n",
            "Step: 3 Temperature: 37 Acción: 0\n",
            "Step: 4 Temperature: 38 Acción: 1\n",
            "Step: 5 Temperature: 37 Acción: 0\n",
            "Step: 6 Temperature: 38 Acción: 1\n",
            "Step: 7 Temperature: 37 Acción: 0\n",
            "Step: 8 Temperature: 38 Acción: 1\n",
            "Step: 9 Temperature: 37 Acción: 0\n",
            "Step: 10 Temperature: 38 Acción: 1\n",
            "Step: 11 Temperature: 37 Acción: 0\n",
            "Step: 12 Temperature: 38 Acción: 1\n",
            "Step: 13 Temperature: 37 Acción: 0\n",
            "Step: 14 Temperature: 38 Acción: 1\n",
            "Step: 15 Temperature: 37 Acción: 0\n",
            "Step: 16 Temperature: 38 Acción: 1\n",
            "Step: 17 Temperature: 37 Acción: 0\n",
            "Step: 18 Temperature: 38 Acción: 1\n",
            "Step: 19 Temperature: 37 Acción: 0\n",
            "Step: 20 Temperature: 38 Acción: 1\n",
            "Step: 21 Temperature: 37 Acción: 0\n",
            "Step: 22 Temperature: 38 Acción: 1\n",
            "Step: 23 Temperature: 37 Acción: 0\n",
            "Step: 24 Temperature: 38 Acción: 1\n",
            "Step: 25 Temperature: 37 Acción: 0\n",
            "Step: 26 Temperature: 38 Acción: 1\n",
            "Step: 27 Temperature: 37 Acción: 0\n",
            "Step: 28 Temperature: 38 Acción: 1\n",
            "Step: 29 Temperature: 37 Acción: 0\n",
            "Step: 30 Temperature: 38 Acción: 1\n"
          ]
        }
      ],
      "source": [
        "# Define a function to control the shower temperature using the trained Q-table\n",
        "def control_shower_with_q_table():\n",
        "    current_temp = np.random.randint(LOW_TEMP-5, HIGH_TEMP+5 + 1)\n",
        "    print(\"Initial temperature:\", current_temp)\n",
        "    for step in range(MAX_STEPS_PER_EPISODE):\n",
        "        state = int(current_temp - LOW_TEMP)\n",
        "        action = np.argmax(q_table[state, :])\n",
        "\n",
        "        # Apply the action\n",
        "        if action == 0:  # Decrease temperature\n",
        "            current_temp -= 1\n",
        "        elif action == 1:  # Increase temperature\n",
        "            current_temp += 1\n",
        "\n",
        "        # Clip temperature to stay within limits\n",
        "        current_temp = np.clip(current_temp, LOW_TEMP, HIGH_TEMP)\n",
        "\n",
        "        print(\"Step:\", step + 1, \"Temperature:\", current_temp, \"Acción:\", action)\n",
        "\n",
        "        if current_temp == LOW_TEMP or current_temp == HIGH_TEMP:\n",
        "            break\n",
        "\n",
        "# Demonstrate the performance of the trained Q-table\n",
        "control_shower_with_q_table()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5542e8a0-bb24-4a87-b3cc-03383c52fd5f",
      "metadata": {
        "id": "5542e8a0-bb24-4a87-b3cc-03383c52fd5f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}